{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "# my package\n",
    "from utils.sparrowpy.data_science import modeling\n",
    "from utils.sparrowpy.data_engg import sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://postgres:postgres@localhost:5432/dvd_rental\n",
      "\n",
      "    SELECT \n",
      "        COUNT(r.rental_id) AS rental_count, \n",
      "        DATE(r.rental_date) as rental_date\n",
      "    FROM rental r\n",
      "    JOIN inventory i ON r.inventory_id = i.inventory_id\n",
      "    where extract(year from date(r.rental_date)) = 2005\n",
      "    GROUP BY DATE(r.rental_date)\n",
      "    ORDER BY rental_date;\n",
      "    \n",
      "             rental_count\n",
      "rental_date              \n",
      "2005-05-24              8\n",
      "2005-05-25            137\n",
      "2005-05-26            174\n",
      "2005-05-27            166\n",
      "2005-05-28            196\n",
      "...                   ...\n",
      "2005-08-19            628\n",
      "2005-08-20            624\n",
      "2005-08-21            659\n",
      "2005-08-22            626\n",
      "2005-08-23            598\n",
      "\n",
      "[92 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sparrow\\AppData\\Local\\Temp\\ipykernel_53664\\1561763527.py:16: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.resample('D').sum().fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "df = sql.get_table_df(\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        COUNT(r.rental_id) AS rental_count, \n",
    "        DATE(r.rental_date) as rental_date\n",
    "    FROM rental r\n",
    "    JOIN inventory i ON r.inventory_id = i.inventory_id\n",
    "    where extract(year from date(r.rental_date)) = 2005\n",
    "    GROUP BY DATE(r.rental_date)\n",
    "    ORDER BY rental_date;\n",
    "    \"\"\"\n",
    ")\n",
    "df\n",
    "df['rental_date'] = pd.to_datetime(df['rental_date'])\n",
    "df.set_index('rental_date', inplace=True)\n",
    "df = df.resample('D').sum().fillna(method='ffill') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (85, 7, 1)\n",
      "y shape: (85, 1)\n"
     ]
    }
   ],
   "source": [
    "rental_data = df\n",
    "rental_data = rental_data.sort_index()\n",
    "rental_data_daily = rental_data.resample('D').sum()\n",
    "rental_data_daily.fillna(0, inplace=True)\n",
    "\n",
    "# Scale the rental count data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rental_counts = rental_data_daily['rental_count'].values.reshape(-1, 1)  # Reshape to 2D\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "rental_counts_scaled = scaler.fit_transform(rental_counts)\n",
    "\n",
    "# 3. Create time series sequences\n",
    "def create_sequences(data, time_steps):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        sequences.append(data[i:i+time_steps])\n",
    "        labels.append(data[i+time_steps])  # The next rental count is the label\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "time_steps = 7\n",
    "X, y = create_sequences(rental_counts_scaled, time_steps)\n",
    "\n",
    "# Reshape data for LSTM input\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))  # 3D shape: (samples, time_steps, features)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")  # (samples, time_steps, 1)\n",
    "print(f\"y shape: {y.shape}\")  # (samples, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sparrow\\.conda\\envs\\py12\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 326ms/step - loss: 0.1488 - val_loss: 0.3498\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.1196 - val_loss: 0.3048\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1038 - val_loss: 0.2789\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1088 - val_loss: 0.2725\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1059 - val_loss: 0.2729\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0988 - val_loss: 0.2714\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1018 - val_loss: 0.2587\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0973 - val_loss: 0.2453\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0974 - val_loss: 0.2345\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0924 - val_loss: 0.2280\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dense(1))  # Output layer to predict rentals\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
      "R2: -119344.61\n",
      "MAE: 144.90\n",
      "RMSE: 155.16\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "# Ensure y_pred is reshaped correctly\n",
    "# Inverse scaling to get actual values\n",
    "y_pred_inverse = scaler.inverse_transform(y_pred)\n",
    "r2 = r2_score(y_test, y_pred_inverse)\n",
    "mae = mean_absolute_error(y_test, y_pred_inverse)\n",
    "rmse = root_mean_squared_error(y_test, y_pred_inverse)\n",
    "\n",
    "print(f\"R2: {r2:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000022BE4455EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "            Predicted Demand\n",
      "2005-08-24        277.890564\n",
      "2005-08-25        262.622986\n",
      "2005-08-26        242.180115\n",
      "2005-08-27        221.241913\n",
      "2005-08-28        202.134186\n",
      "2005-08-29        185.490097\n",
      "2005-08-30        172.382919\n"
     ]
    }
   ],
   "source": [
    "# 4. Predicting the next 7 days of demand\n",
    "# Get the last time_steps of the training data\n",
    "last_sequence = rental_counts_scaled[-time_steps:]  # Last 7 days\n",
    "predictions = []\n",
    "\n",
    "# Predicting for the next 7 days\n",
    "for _ in range(7):\n",
    "    # Reshape for LSTM input\n",
    "    input_sequence = last_sequence.reshape((1, time_steps, 1))\n",
    "    prediction = model.predict(input_sequence)\n",
    "    predictions.append(prediction[0, 0])  # Get the predicted value\n",
    "    \n",
    "    # Update the last_sequence for the next prediction\n",
    "    last_sequence = np.append(last_sequence[1:], prediction)\n",
    "\n",
    "# Inverse transform to get the original scale\n",
    "predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "\n",
    "# Prepare a DataFrame for the predicted demand\n",
    "last_date = rental_data_daily.index[-1]  # Get the last date from training\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=7)\n",
    "predicted_demand_df = pd.DataFrame(predictions, index=future_dates, columns=['Predicted Demand'])\n",
    "\n",
    "print(predicted_demand_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
