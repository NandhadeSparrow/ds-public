{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# my package\n",
    "from utils.sparrowpy.data_science import modeling\n",
    "from utils.sparrowpy.data_engg import sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://postgres:postgres@localhost:5432/dvd_rental\n",
      "\n",
      "    select \n",
      "        round(avg(ccnt.country_id), 2) as country_id,\n",
      "        round(avg(cat.category_id), 2) as category_id,\n",
      "        round(avg(st.store_id), 2) as store_id,\n",
      "        round(avg(stf.staff_id), 2) as staff_id,\n",
      "        round(avg(pay.amount), 2) as amount,\n",
      "        round(avg(EXTRACT(DAY FROM (rnt.return_date - rnt.rental_date))- film.rental_duration), 2) AS return_delay,\n",
      "        round(max(c.active), 2) as active\n",
      "    from\n",
      "        customer c\n",
      "        join address cad \n",
      "            on c.address_id = cad.address_id\n",
      "        join city\n",
      "            on cad.city_id = city.city_id\n",
      "        join country as ccnt\n",
      "            on city.country_id = ccnt.country_id\n",
      "        join store as st\n",
      "            on c.store_id = st.store_id\n",
      "        join payment as pay\n",
      "            on c.customer_id = pay.customer_id\n",
      "        join rental as rnt\n",
      "            on c.customer_id = rnt.customer_id\n",
      "        join inventory as inv\n",
      "            on rnt.inventory_id = inv.inventory_id\n",
      "        join film\n",
      "            on inv.film_id = film.film_id\n",
      "        join film_category as cat\n",
      "            on film.film_id = cat.film_id\n",
      "        join staff as stf\n",
      "            on rnt.staff_id = stf.staff_id\n",
      "\n",
      "\n",
      "    group by\n",
      "        c.customer_id\n",
      "    \n",
      "    country_id category_id store_id staff_id amount return_delay active\n",
      "0        24.00        8.20     1.00     1.40   4.92        -0.03   1.00\n",
      "1        67.00        8.83     1.00     1.52   4.04        -0.26   1.00\n",
      "2       102.00        8.09     1.00     1.55   5.09        -0.09   1.00\n",
      "3        60.00        8.14     2.00     1.43   4.67        -0.17   1.00\n",
      "4        23.00        8.41     2.00     1.59   4.89         0.13   1.00\n",
      "..         ...         ...      ...      ...    ...          ...    ...\n",
      "594      46.00        9.10     2.00     1.65   4.75         0.95   1.00\n",
      "595     105.00        8.69     2.00     1.47   4.12        -0.47   1.00\n",
      "596      23.00        7.27     2.00     1.64   3.06        -0.75   0.00\n",
      "597      80.00        8.55     2.00     1.50   4.46        -1.82   1.00\n",
      "598      79.00        9.63     1.00     1.52   4.70        -0.11   1.00\n",
      "\n",
      "[599 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df = sql.get_table_df(\n",
    "    query = \"\"\"\n",
    "    select \n",
    "        round(avg(ccnt.country_id), 2) as country_id,\n",
    "        round(avg(cat.category_id), 2) as category_id,\n",
    "        round(avg(st.store_id), 2) as store_id,\n",
    "        round(avg(stf.staff_id), 2) as staff_id,\n",
    "        round(avg(pay.amount), 2) as amount,\n",
    "        round(avg(EXTRACT(DAY FROM (rnt.return_date - rnt.rental_date))- film.rental_duration), 2) AS return_delay,\n",
    "        round(max(c.active), 2) as active\n",
    "    from\n",
    "        customer c\n",
    "        join address cad \n",
    "            on c.address_id = cad.address_id\n",
    "        join city\n",
    "            on cad.city_id = city.city_id\n",
    "        join country as ccnt\n",
    "            on city.country_id = ccnt.country_id\n",
    "        join store as st\n",
    "            on c.store_id = st.store_id\n",
    "        join payment as pay\n",
    "            on c.customer_id = pay.customer_id\n",
    "        join rental as rnt\n",
    "            on c.customer_id = rnt.customer_id\n",
    "        join inventory as inv\n",
    "            on rnt.inventory_id = inv.inventory_id\n",
    "        join film\n",
    "            on inv.film_id = film.film_id\n",
    "        join film_category as cat\n",
    "            on film.film_id = cat.film_id\n",
    "        join staff as stf\n",
    "            on rnt.staff_id = stf.staff_id\n",
    "\n",
    "\n",
    "    group by\n",
    "        c.customer_id\n",
    "    \"\"\"\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'active'\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "\n",
    "num_features = X.shape[1]\n",
    "\n",
    "# Train-test split\n",
    "X = np.array(X, dtype=float) \n",
    "y = np.array(y, dtype=float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    # Convert predictions to binary values\n",
    "    y_pred = tf.round(y_pred)  # Assuming binary classification\n",
    "    tp = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32))  # True Positives\n",
    "    tn = tf.reduce_sum(tf.cast((1 - y_true) * (1 - y_pred), tf.float32))  # True Negatives\n",
    "    fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, tf.float32))  # False Positives\n",
    "    fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), tf.float32))  # False Negatives\n",
    "    \n",
    "    precision = tp / (tp + fp + tf.keras.backend.epsilon())\n",
    "    recall = tp / (tp + fn + tf.keras.backend.epsilon())\n",
    "    \n",
    "    return 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sparrow\\.conda\\envs\\py12\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Sparrow\\.conda\\envs\\py12\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.2333 - loss: 1.0452 - val_accuracy: 0.1667 - val_loss: 0.8966\n",
      "Epoch 2/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2900 - loss: 0.9902 - val_accuracy: 0.2917 - val_loss: 0.8406\n",
      "Epoch 3/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3004 - loss: 0.9257 - val_accuracy: 0.3542 - val_loss: 0.7907\n",
      "Epoch 4/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3212 - loss: 0.8904 - val_accuracy: 0.3958 - val_loss: 0.7496\n",
      "Epoch 5/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4789 - loss: 0.8316 - val_accuracy: 0.5417 - val_loss: 0.7159\n",
      "Epoch 6/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4666 - loss: 0.7989 - val_accuracy: 0.6458 - val_loss: 0.6890\n",
      "Epoch 7/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5714 - loss: 0.7439 - val_accuracy: 0.6875 - val_loss: 0.6661\n",
      "Epoch 8/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6007 - loss: 0.7237 - val_accuracy: 0.7917 - val_loss: 0.6462\n",
      "Epoch 9/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6611 - loss: 0.7027 - val_accuracy: 0.8333 - val_loss: 0.6287\n",
      "Epoch 10/10\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6814 - loss: 0.6868 - val_accuracy: 0.8542 - val_loss: 0.6135\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m36\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">293</span> (1.15 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m293\u001b[0m (1.15 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97</span> (388.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m97\u001b[0m (388.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">196</span> (788.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m196\u001b[0m (788.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build the ANN model with Dropout\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(units=8, input_dim=num_features))\n",
    "model.add(Dropout(0.3))  \n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# model.add(Dense(units=256, activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# model.add(Dense(units=128, activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# model.add(Dense(units=64, activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# model.add(Dense(units=32, activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# model.add(Dense(units=16, activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Dense(units=4))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.3))  \n",
    "\n",
    "# model.add(Dense(units=4, activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "# model.add(Dense(units=2, activation='relu'))\n",
    "# model.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Test Accuracy: 0.8750\n",
      "Test f1 score: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1score = f1_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test f1 score: {f1score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql+psycopg2://postgres:postgres@localhost:5432/dvd_rental\n",
      "\n",
      "    select \n",
      "        category_id,\n",
      "        name\n",
      "    from\n",
      "        category\n",
      "    group by category_id\n",
      "    order by category_id\n",
      "\n",
      "    \n",
      "{'Action': 1, 'Animation': 2, 'Children': 3, 'Classics': 4, 'Comedy': 5, 'Documentary': 6, 'Drama': 7, 'Family': 8, 'Foreign': 9, 'Games': 10, 'Horror': 11, 'Music': 12, 'New': 13, 'Sci-Fi': 14, 'Sports': 15, 'Travel': 16}\n",
      "postgresql+psycopg2://postgres:postgres@localhost:5432/dvd_rental\n",
      "\n",
      "    select \n",
      "        country_id,\n",
      "        country\n",
      "    from\n",
      "        country\n",
      "    group by country_id\n",
      "    order by country\n",
      "\n",
      "    \n",
      "{'Afghanistan': 1, 'Algeria': 2, 'American Samoa': 3, 'Angola': 4, 'Anguilla': 5, 'Argentina': 6, 'Armenia': 7, 'Australia': 8, 'Austria': 9, 'Azerbaijan': 10, 'Bahrain': 11, 'Bangladesh': 12, 'Belarus': 13, 'Bolivia': 14, 'Brazil': 15, 'Brunei': 16, 'Bulgaria': 17, 'Cambodia': 18, 'Cameroon': 19, 'Canada': 20, 'Chad': 21, 'Chile': 22, 'China': 23, 'Colombia': 24, 'Congo, The Democratic Republic of the': 25, 'Czech Republic': 26, 'Dominican Republic': 27, 'Ecuador': 28, 'Egypt': 29, 'Estonia': 30, 'Ethiopia': 31, 'Faroe Islands': 32, 'Finland': 33, 'France': 34, 'French Guiana': 35, 'French Polynesia': 36, 'Gambia': 37, 'Germany': 38, 'Greece': 39, 'Greenland': 40, 'Holy See (Vatican City State)': 41, 'Hong Kong': 42, 'Hungary': 43, 'India': 44, 'Indonesia': 45, 'Iran': 46, 'Iraq': 47, 'Israel': 48, 'Italy': 49, 'Japan': 50, 'Kazakstan': 51, 'Kenya': 52, 'Kuwait': 53, 'Latvia': 54, 'Liechtenstein': 55, 'Lithuania': 56, 'Madagascar': 57, 'Malawi': 58, 'Malaysia': 59, 'Mexico': 60, 'Moldova': 61, 'Morocco': 62, 'Mozambique': 63, 'Myanmar': 64, 'Nauru': 65, 'Nepal': 66, 'Netherlands': 67, 'New Zealand': 68, 'Nigeria': 69, 'North Korea': 70, 'Oman': 71, 'Pakistan': 72, 'Paraguay': 73, 'Peru': 74, 'Philippines': 75, 'Poland': 76, 'Puerto Rico': 77, 'Romania': 78, 'Runion': 79, 'Russian Federation': 80, 'Saint Vincent and the Grenadines': 81, 'Saudi Arabia': 82, 'Senegal': 83, 'Slovakia': 84, 'South Africa': 85, 'South Korea': 86, 'Spain': 87, 'Sri Lanka': 88, 'Sudan': 89, 'Sweden': 90, 'Switzerland': 91, 'Taiwan': 92, 'Tanzania': 93, 'Thailand': 94, 'Tonga': 95, 'Tunisia': 96, 'Turkey': 97, 'Turkmenistan': 98, 'Tuvalu': 99, 'Ukraine': 100, 'United Arab Emirates': 101, 'United Kingdom': 102, 'United States': 103, 'Venezuela': 104, 'Vietnam': 105, 'Virgin Islands, U.S.': 106, 'Yemen': 107, 'Yugoslavia': 108, 'Zambia': 109}\n",
      "postgresql+psycopg2://postgres:postgres@localhost:5432/dvd_rental\n",
      "\n",
      "    select \n",
      "        staff_id,\n",
      "        first_name\n",
      "    from\n",
      "        staff\n",
      "    group by staff_id\n",
      "    order by first_name\n",
      "\n",
      "    \n",
      "{'Jon': 2, 'Mike': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'category_id': {'Action': 1,\n",
       "  'Animation': 2,\n",
       "  'Children': 3,\n",
       "  'Classics': 4,\n",
       "  'Comedy': 5,\n",
       "  'Documentary': 6,\n",
       "  'Drama': 7,\n",
       "  'Family': 8,\n",
       "  'Foreign': 9,\n",
       "  'Games': 10,\n",
       "  'Horror': 11,\n",
       "  'Music': 12,\n",
       "  'New': 13,\n",
       "  'Sci-Fi': 14,\n",
       "  'Sports': 15,\n",
       "  'Travel': 16},\n",
       " 'country_id': {'Afghanistan': 1,\n",
       "  'Algeria': 2,\n",
       "  'American Samoa': 3,\n",
       "  'Angola': 4,\n",
       "  'Anguilla': 5,\n",
       "  'Argentina': 6,\n",
       "  'Armenia': 7,\n",
       "  'Australia': 8,\n",
       "  'Austria': 9,\n",
       "  'Azerbaijan': 10,\n",
       "  'Bahrain': 11,\n",
       "  'Bangladesh': 12,\n",
       "  'Belarus': 13,\n",
       "  'Bolivia': 14,\n",
       "  'Brazil': 15,\n",
       "  'Brunei': 16,\n",
       "  'Bulgaria': 17,\n",
       "  'Cambodia': 18,\n",
       "  'Cameroon': 19,\n",
       "  'Canada': 20,\n",
       "  'Chad': 21,\n",
       "  'Chile': 22,\n",
       "  'China': 23,\n",
       "  'Colombia': 24,\n",
       "  'Congo, The Democratic Republic of the': 25,\n",
       "  'Czech Republic': 26,\n",
       "  'Dominican Republic': 27,\n",
       "  'Ecuador': 28,\n",
       "  'Egypt': 29,\n",
       "  'Estonia': 30,\n",
       "  'Ethiopia': 31,\n",
       "  'Faroe Islands': 32,\n",
       "  'Finland': 33,\n",
       "  'France': 34,\n",
       "  'French Guiana': 35,\n",
       "  'French Polynesia': 36,\n",
       "  'Gambia': 37,\n",
       "  'Germany': 38,\n",
       "  'Greece': 39,\n",
       "  'Greenland': 40,\n",
       "  'Holy See (Vatican City State)': 41,\n",
       "  'Hong Kong': 42,\n",
       "  'Hungary': 43,\n",
       "  'India': 44,\n",
       "  'Indonesia': 45,\n",
       "  'Iran': 46,\n",
       "  'Iraq': 47,\n",
       "  'Israel': 48,\n",
       "  'Italy': 49,\n",
       "  'Japan': 50,\n",
       "  'Kazakstan': 51,\n",
       "  'Kenya': 52,\n",
       "  'Kuwait': 53,\n",
       "  'Latvia': 54,\n",
       "  'Liechtenstein': 55,\n",
       "  'Lithuania': 56,\n",
       "  'Madagascar': 57,\n",
       "  'Malawi': 58,\n",
       "  'Malaysia': 59,\n",
       "  'Mexico': 60,\n",
       "  'Moldova': 61,\n",
       "  'Morocco': 62,\n",
       "  'Mozambique': 63,\n",
       "  'Myanmar': 64,\n",
       "  'Nauru': 65,\n",
       "  'Nepal': 66,\n",
       "  'Netherlands': 67,\n",
       "  'New Zealand': 68,\n",
       "  'Nigeria': 69,\n",
       "  'North Korea': 70,\n",
       "  'Oman': 71,\n",
       "  'Pakistan': 72,\n",
       "  'Paraguay': 73,\n",
       "  'Peru': 74,\n",
       "  'Philippines': 75,\n",
       "  'Poland': 76,\n",
       "  'Puerto Rico': 77,\n",
       "  'Romania': 78,\n",
       "  'Runion': 79,\n",
       "  'Russian Federation': 80,\n",
       "  'Saint Vincent and the Grenadines': 81,\n",
       "  'Saudi Arabia': 82,\n",
       "  'Senegal': 83,\n",
       "  'Slovakia': 84,\n",
       "  'South Africa': 85,\n",
       "  'South Korea': 86,\n",
       "  'Spain': 87,\n",
       "  'Sri Lanka': 88,\n",
       "  'Sudan': 89,\n",
       "  'Sweden': 90,\n",
       "  'Switzerland': 91,\n",
       "  'Taiwan': 92,\n",
       "  'Tanzania': 93,\n",
       "  'Thailand': 94,\n",
       "  'Tonga': 95,\n",
       "  'Tunisia': 96,\n",
       "  'Turkey': 97,\n",
       "  'Turkmenistan': 98,\n",
       "  'Tuvalu': 99,\n",
       "  'Ukraine': 100,\n",
       "  'United Arab Emirates': 101,\n",
       "  'United Kingdom': 102,\n",
       "  'United States': 103,\n",
       "  'Venezuela': 104,\n",
       "  'Vietnam': 105,\n",
       "  'Virgin Islands, U.S.': 106,\n",
       "  'Yemen': 107,\n",
       "  'Yugoslavia': 108,\n",
       "  'Zambia': 109},\n",
       " 'staff_id': {'Jon': 2, 'Mike': 1}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoders = {}\n",
    "\n",
    "\n",
    "df_encoder = sql.get_table_df(\n",
    "    query = \"\"\"\n",
    "    select \n",
    "        category_id,\n",
    "        name\n",
    "    from\n",
    "        category\n",
    "    group by category_id\n",
    "    order by category_id\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "result_dict = df_encoder.set_index('name')['category_id'].to_dict()\n",
    "print(result_dict)\n",
    "encoders['category_id'] = result_dict\n",
    "\n",
    "\n",
    "df_encoder = sql.get_table_df(\n",
    "    query = \"\"\"\n",
    "    select \n",
    "        country_id,\n",
    "        country\n",
    "    from\n",
    "        country\n",
    "    group by country_id\n",
    "    order by country\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "result_dict = df_encoder.set_index('country')['country_id'].to_dict()\n",
    "print(result_dict)\n",
    "encoders['country_id'] = result_dict\n",
    "\n",
    "\n",
    "df_encoder = sql.get_table_df(\n",
    "    query = \"\"\"\n",
    "    select \n",
    "        staff_id,\n",
    "        first_name\n",
    "    from\n",
    "        staff\n",
    "    group by staff_id\n",
    "    order by first_name\n",
    "\n",
    "    \"\"\"\n",
    ")\n",
    "result_dict = df_encoder.set_index('first_name')['staff_id'].to_dict()\n",
    "print(result_dict)\n",
    "encoders['staff_id'] = result_dict\n",
    "\n",
    "\n",
    "encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(prediction):\n",
    "    prediction = round(float(prediction[0][0]))\n",
    "    if prediction >= 0.5:\n",
    "        return \"The model predicts: **The customer will not churn**\"\n",
    "    else:\n",
    "        return \"The model predicts: **The customer will churn**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling.save_model(\n",
    "    model_name = 'churn',\n",
    "    target = target,\n",
    "    model = model,\n",
    "    model_format='keras',\n",
    "    scaler = scaler,\n",
    "    features = list(df.drop(target, axis=1).columns),\n",
    "    result = result,\n",
    "    encoders = encoders\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
